# Interpretable Machine Learning and Sensitivity Analysis


* Read Risk Minimization mindset first
* Also called explainable AI, XAI
* related to sensitivity analysis
* Idea: Fit model using risk minimization, take best model, analyze model with iml methods
* In other words: Build a model of the world with focus on optimization, not inner structure.
* why own mindset:
  * distinct from pure risk minimization: Pure risk minimization does not care about the $f$. But iml does care.
  * distinct from statistical mdoeling: no probability distributions and so on required
  * certain way to see the world: the best model is based on optimization. but we can learn from that model.
* Really good for debugging, and mostly used for that
* Builds on my own work
* But there is the possiblity to see the groundtruth function
* Therefre has some frequentist views on the world
* Modification: Already build interpretability into the model. Not the pure archetype here, as we don't do pure risk minimization any longer, but takes on elements of statistical learning, at least the DGP thinking.
  

<!-- TODO: Visualize black box sensitivity analysis -->

<!-- TODO: Visualize PDP as example -->

