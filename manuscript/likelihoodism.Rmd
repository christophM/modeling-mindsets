# Likelihoodism

<!-- summary of likelihoodism -->
Apart from [frequentist inference](#frequentism) and [Bayesian inference](#bayesian), there is -- at least -- a third interpretation of statistical models: likelihoodism.
In short, likelihoodism states that all relevant model information is captured in the likelihood function.
This likelihood-sufficiency sets it apart from frequentism, which depends on the experimental design and imagined long-run frequencies.
This likelihood-sufficiency sets it also apart from Bayesianism, because Bayesians also incorporate prior probability distributions of the parameters.
Likelihoodism solely builds on the likelihood function for relating to the real world.

<!-- less popular -->
I studied statistics for 5 years, and never heard about likelihoodism.
It's a minor statistical philosophy.
It's minor for a reason, to which we will come later.
Nonetheless, I think we can learn from it, especially to sharpen our understanding of how frequentism and Bayesianism work.

<!-- short reminder: likelihood -->
A short reminder of the likelihood function:
The likelihood function is the probability function of the data.
But the data are seen as fixed, and the likelihood is a function of the model parameters:

$$L(\theta | X) = P(X = x | \theta)$$

<!-- likelihood principle -->
The likelihood principle is central to likelihoodism.
The likelihood principle says that, given a statistical model, all relevant information about the model parameters from the data is contained in the likelihood function.
In more concrete terms, all information about the distributional parameters $\theta$ is contained in data $X$.
Two likelihood functions contain the same evidence when they are proportional to each other.
Frequentist inference violates the likelihood principle, as we will see later in this chapter.
Bayesian inference coheres to the likelihood principle.
While Bayesians use prior information about the parameters, all parameter-relevant information contained in the data is infused in the likelihood.

<!-- building models -->
When likelihoodists build models, it is very similar to how frequentist build their models.
The big difference is in the interpetation of the models and how likehoodists deal with results.
Or rather, it's in what likelihoodists do NOT do.
Likelihoodists reject the idea of long-run frequences as the frequentists rely on.
This also means that likelihoodists don't use hypothesis tests, p-value, confidence intervals and so on.
Likelihoodists also reject the Bayesian interpretation of probability.
They can't rely on posterior distributions, and their interpretation as beliefs about the parameters.
How then, can likelihoodists say anything about the world with their models?

## Modeling and Likelihood Ratios

<!-- comparing models -->
When all is contained in the likelihood, then it is obvious that we should be comparing likelihoods.
For likelihoodists, building a model means creating a hypothesis.
The hypothesis can be: Daily vitamin D intake reduces the number of colds per year.
An alternative hypothesis could be: Daily vitamin D intake reduces the number of colds per year, but also whether the person is a couch potatoe or very active.
Both hypotheses can be modelled.
Let's say $Y$ is the number of colds, $X_1$ is the binary information whether someone takes vitamin D (yes/no) and $X_2$ the random variable representing whether the person is a couch potatoe (potatoe/active). 
As the outcome is a count, the statistician chooses a Poisson distribution for the outcome:

$$Y | X_1, X_2 \sim Poi(\lambda)$$ 

The parameter $\lambda$ describes the intensity of how often colds occur.  
To connect the random variables $X_1$ and $X_2$ with the outcome, we say that the expected outcome is a function of the random variables.

$$E(Y | X_1, X_2) = e^{\beta_0 + \beta_1 X_1}$$

That's for the first model, where we only have vitamin D as variable.
The other model also contains another variable:

$$E(Y | X_1, X_2) = e^{\beta_0 + \beta_1 X_1 + \beta_2 X_2}$$

Both can then be optimized with a maximum likelihood appraoch, as presented in [chapter statistical modeling](#statistical-modeling).
This gives us the best fitting parameters.
But it gives us something else as well.
And we haven't talked about it yet.
We get the likelihood.
Which is a number that can be interpreted as the likelihood of the model and its parameterization.
This means for our made-up example, we get two models with different parameter estimates and also two likelihood numbers.

<!-- comparing likelihoods -->
This brings us to likelihood ratios.
It's a simple equation: We divide the likelihood of model for hypothesis $H_1$ by the likelihood of model hypothesis $H_2$:

$$\frac{L(H_1|X)}{L(H_2|X)}$$

This allows one to compare the likelihood of two hypothesis.
A likelihood ratio larger than 1 favors $H_1$, a ratio smaller than 1 favors $H_2$.

<!-- LR in other mindsets -->
Likelihood ratios are also used in Bayesianism and frequentism.
IN Bayesianism as Bayes factor, also for model selection.
IN frequentism likelihood rations are often used as test statistics for hypothesis tests.


<!-- LR in likelihoodism -->
So, inference in the case of likelihoodism simply means accepting the hypothesis that has a larger likelihood?
There are only likelihoods of different hypothesis, and we use the one with LR larger than one.
Both likelihoods are the results of data.
Therefore, they are subject to variance.

<!-- other problem -->
There is another problem: We can't compare likelihoods for different model classes.
If we would not encode our target $Y$ as number of colds, but as a binary target, like "Three or more colds in a year", then we can't compare the likelihoods of these models.
The first model would assume a Poisson distribution of the target, the second one a Binomial distribution.
The likelihoods would not be comparable any more.

<!-- using likelihood intervals -->
One approximation to make allow making decision based on the likelihood ratio: likelihood intervals.
Likelihood intervals or regions are the likelihoodist analogue to frequentist confidence interval and Bayesian credible intervals.
Confidence intervals are interpreted as coverage probability  and credible intervals as posterior belief about the parameter.
The interpretation of likelihood regions is in terms of relative likelihood.
The likelihood interval of a model parameter $\theta$ (like the coefficient) is the set of all $\theta$ values that yield a relative likelihood greater than a certain threshold:

$$\left\{\theta: \frac{L(\theta| X)}{L(\hat{\theta}| X)} \geq \frac{p}{100}\right\}$$

The $\hat{\theta}$ is the "optimal" parameter that statistician found using maximum likelihood (or similar optimization methods).
Let's say for a logistic regression model coefficient $\beta_j$: $\hat{\beta}_j = 1.1$. <!-- fix vim_ -->
Then an interval might be $[0.9; 1.3]$.
The constant $p$ serves a similar function lke the alpha level for confidence intervals:
It decides the size of the region.
A $p = 1$ would mean that only the maximum likelihood estimate is in teh interval.
A $p = 0$ would mean that all possible parameters are in the interval.
A $p=0.05$ would mean that all $\theta$ with up to a drop of five percent drop in the likelihood are in the interval.  


## Why Frequentism Violates the Likelihood Principle

Personally, I first thought that likelihoodism is just frequentism without hypothesis tests.
But the differences between the two run deeper.
Likelihoodism adheres to the likelihood principle, frequentism violates it.

<!-- motivation for example -->
The following example shows how frequentism violates the likelihood principle, but also a great illustration of the core idea of likelihoodism.
<!-- starting coin example -->
Suppose we have a coin, and we want to figure out whether it's fair, or whether head turns up too often.
Let $\theta$ be the probability of head.
We have two different hypothesis:

So: $H_0: \theta = 0.5$ und $H_1: \theta > 0.5$

The $H_0$-hypothesis basically says that the coin is fair.
And $H_1$ claims that head coms up more often than tails.
We say that $X$ is the number of heads.
And $Y$ the number of trials.

<!-- two types of experiments -->
Let's pretend the outcomes of the two experiments are the following:

1. Toss coin 12 times. We observe 9 heads out of the 12 tosses.
1. Toss coin until 3 times tail was observed. 

Two experiments with the same outcome, but different procedures.
In experiment 1) we fixed $Y$, the number of tosses.
IN experiment 2), we fixed $X$ the number of heads.

<!-- likelihoodist view of the experiment -->
In the likelihoodist view, both experiments have the same likelihood, up to some constant factor.
They are proportional to each other:

$$L(\theta | X = 3) = \binom{12}{3} \theta^3 (1 - \theta)^9 (1 - \theta)^9 = 220 \theta^3 (1 - \theta)^9 $$

And for experiment number two:

<!-- the 2 out of 11 results from the fact that the last toss must be a head -->
$$L(\theta | Y = 12) = \binom{11}{2} \theta^3 (1 - \theta)^9 (1 - \theta)^9 = 55 \theta^3 (1 - \theta)^9$$

<!-- The Likelihood Principle: https://www2.isye.gatech.edu/isyebayes/bank/handout2.pdf -->
So the likelihoodists say that both experiments carry the same evidence.

<!-- Frequentist view on the experiments -->
However, frequentists would come to a different conclusion. [^vidakovic9999]
Before we dive into mathematics, how can it even be, from a point of intuition, that there are different results?
In short: frequentists also incorporate results that did not happen.
For hypothesis tests, $H_1$ often framed as some more extreme event to happen.
But we never observed these, we just take what we observed (here 9 out of 12 are tail) and pretend that we observe the event more often.
Due to the different framing on whether the 9 heads or the 12 trials are fixed, the $H_1$ hypothesis either includes probabilities of fictional experiments where 9,11, or 12 heads were observed.
Or, in the other framing, it includes all experiments where we observed more than 12 repetitions.
Remember number of tails = 3 is fixed, so more repetitions means in favor that $\theta > 0.5$.

When testing $H_0$ vs. $H_1$, we can see:

$$P(X \geq 9| H_0) = \sum_{x = 9}^{12} \binom{x}{12} 0.5^x (1 - 0.5)^{12 - x} = 0.073$$

So when we set the significance level $\alpha = 0.05$ we would not reject the hypothesis of a fair coin.

But for the other experiment:
Here we have to assume a Negative Binomial distribution:

$$P(Y \geq 9 | H_0) = \sum_{y=9}^{\infty}\binom{3 + y - 1}{2} 0.5^y 0.5^3 = 0.0327$$

Why is that?
Because in the second experiment, we have, in the frequentist view, consider all events where also $X==3$ but the numbr of trials running to infinity.
Here we get a significant result and would reject the $H_0$-hypothesis of a fair coin.

<!--

## Lack of priors

Let's take a silly example:

You eat rice.
It tastes funny. A bit like whiskey.
It could be either because it had gone bad, or someone has put something in it.
You have had bad rice, it had tasted differently.
But the taste would be plausible if someone had put whiskey into the rice.
So, two opposing hypotheses:

$$P(funny rice | person added whiskey) > P(funny rice|rice bad)$$

But it's much more likely that the rice has gone bad.
Because whiskey-pouring rice-haters are one of the rarest people on earth.
But without prior probabilites, it's not the right result.

-->

## Strengths

* An attractive idea to say that all information is contained in the likelihood. Conforms to the likelihood principle.
* Therefore likelihoodism is also not dependent on the experimental design like frequentism is.
* Likelihoodism inherits all strengths of statistical models.
* No prior distribution needed, and therefore "objective".

## Limitations 

* Likelihood ratio favoring one hypothesis over another does not allow a decision for one model, or not a degree of belief.
* Likelihoodism does not give guidance for action as in frequentism
* Nor does it give degree of believe as in Bayesianism
* Therefore, little practical value
* Likelihoodism has been critizied [^gandenberger2016], because: no use of priors.

[^vidakovic9999]: ISyE8843A, Brani Vidakovic Handout. "1 The Likelihood Principle."

[^gandenberger2016]: Gandenberger, Greg. Why I am not a likelihoodist. Ann Arbor, MI: Michigan Publishing, University of Michigan Library, 2016.

