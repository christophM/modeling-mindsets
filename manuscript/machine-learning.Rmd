# Machine Learning {#machine-learning}

<!-- TODO

* Reread: End of Theory. https://www.wired.com/2008/06/pb-theory/ [@anderson2008end] -> This one is more general and might fit into the model chapter
* Read: https://hal.archives-ouvertes.fr/hal-03474791/
* Write external vs. internal views
* Write about narrow AI mindset

-->


* Machine learning is a computer-first mindset concerned with making a computer "intelligent". 
* A good machine learning model solves a task well: External evaluation of task performance is more important than internal validity of the model.
* Machine learning is an alternative meta mindset to [statistical modeling](#statistical-ml). 
* [Supervised machine learning](#supervised-ml), [unsupervised machine learning](#unsupervised-ml), [reinforcement learning](#reinforcement-learning), and [deep learning](#deep-learning) are specializations of the machine learning mindset.


<!-- motivational introduction -->
It's likely that you used a machine learning powered product today.
You might have asked your smart assistant to read out your agenda for today, used a navigation app to get from A to B, or checked your mostly spam-free e-mails.
Machine learning is used in all these applications to make the product work: speech recognition, traffic jam prediction, and spam classification are just a few examples of what machine learning can do.
These examples show that machine learning is task-oriented.
Statistical modeling, in contrast, is more insight-oriented.

<!-- Artificial intelligence -->
For some, machine learning is not only task-oriented, but rather about making the computer intelligent.
Machine learning is the branch of artificial intelligence that is concerned with learning models directly from data.
The computer improves itself at some task through "experience" aka by learning from data.
The machine learning mindset doesn't tell you **how** the computer shall learn from data.
Machine learner may or may not use random variables.
They might work on a prediction model with a clear definition of when the model is correct, or they might work on clustering where the model is more difficult to evaluate. 
The models can be neural networks, decision trees, density estimators, statistical models and many more.

<!-- not it's own mindset  -->
Given this broad set of tasks and no strict guidelines on how the computer has to learn: Can we really say that machine learning is it's own mindset?
To answer the question, let's first have a look at subsets of tasks.
Typically, machine learning is divided into supervised, unsupervised and reinforcement learning.
Each of these also constitutes a distinct modeling mindset: They contain a specific view on the world, the relationship between the models and the world, and how to judge what a good model is.
The [supervised machine learning](#supervised-ml) mindset frames everything as a prediction or classification problem, and comes with a clear definition of what a good model is: when it generalizes well to new data.
The [reinforcement learning](#reinforcement-learning) mindset sees the world as dynamic, where an actor interacts with an environment guided by a reward.
In the [unsupervised machine learning](#unsupervised-ml) mindset the goal is to find patterns in the data.
What is the commonality shared between all these three mindsets?
Is there a unified machine learning mindset?


```{r ml-venn, fig.cap = "Machine Learning is a subset of artificial intelligence. Within machine learning, there is a an important mindset called supervised machine learning. Overlapping are deep learning approaches.", fig.height = 4, fig.width = 6}
library(ggplot2)
r1 = rectFun(c(0, 0), 2, 3)
r2 = rectFun(c(0.2, -0.1), 1.7, 2.5)
r3 = rectFun(c(0.9, -0.2), 1.4, 1)
r4 = rectFun(c(0.35, -0.4), 0.9, 2)

addBox = function(p, center, height, width, label, lty = 1){
  r1 = rectFun(center, height, width)
  labelpos = c(center[1] - width/2 + 0.05, center[2] + height/2 - 0.05) 
  p +
  geom_path(data = r1, lty = lty) + 
  annotate("text", labelpos[1], labelpos[2], label = label, hjust = 0, vjust = 1)
}


p = ggplot(mapping = aes(x,y)) + theme_void() 
p = addBox(p, c(0, 0), 2, 3, "Artificial Intelligence")
p = addBox(p, c(0.2, -0.1), 1.7, 2.5, "Machine Learning")
p = addBox(p, c(0.9, -0.2), 1.4, 1, "Deep Learning")
p = addBox(p, c(0.35, 0.1), 0.5, 2, "Reinforcement Learning")
p = addBox(p, c(0.35, -0.6), 0.5, 2, "Supervised Learning")

add_cc(p)
```


<!-- yes, ml has core mindset -->
The machine learning mindset might not be as united and principled as [statistical modeling](#statistical-modeling).
But all machine learning approaches have a few things in common.
Let's have a look at what constitutes a good machine learning model and how these models are related to the real world.

<!-- ml is computer-driven -->
As all modeling mindsets in this book, machine learning is based on learning models from data.
As the name suggests, machine learning emphasizes the "machine", the computer.
Machine learning is about making the computer "learn" to solve tasks, such as prediction, recommendation, translation, and clustering.
How is that different from what statisticians do, who also rely on computers?
The motivation for using a computer differs between an archetypical statistician and an archetypical machine learner.
The statistician uses the computer out of convenience and necessity.
Modern statistics wouldn't be possible without a computer.
But the computer is not the starting point.
The starting point is statistical theory.
And the computer is only an aide to apply the statistical theory to data. [^computational-statistics]
The machine learner, in contrast, starts with the computer as the premise.
The machine learner says: "We have this new thing, the computer. How can we make it do intelligent and useful things?"
Machine learning is therefore a computer-first mindset.

<!-- algorithm-producing algorithm -->
Machine learning can be understood as a meta-algorithm:
An algorithm that uses data to produce machine learning models, which are also algorithms.
From a programmers standpoint, machine learning is a paradigm shift:
Machine learning is just a way to "learn" an algorithm from data, instead of programming it directly. [^still-programmed]

<!-- ml is task-driven -->
Machine learning is usually used to solve a task, in contrast to the more insights-driven statistical modeling mindset.
The task can be language translation, image captioning, classification, and so on.
Success of the model is measured in how well the task was solved using some kind of metric.
For prediction and classification the machine learner measures the generalization error for new data.
More concretely, for a classification model it could be the accuracy of getting the classes right in a new dataset.
For clustering, the success metrics usually measure how homogeneous data points in the clusters are and how much the data differ between clusters.
This external focus is also reflected in how research for machine learning works:
Researchers invent a new machine learning algorithm and show that it works by comparing it to other algorithms in some task benchmarks.
The reason why the algorithm works well is often discovered only in later scientific publications, if at all.

<!-- external vs intrinsic motivation -->
We can distinguish external and intrinsic modeling motivation.
The motivation and evaluation of a machine learning model is external, based on task performance.
It's like judging food based on how it tastes.
Statistical modeling is intrinsically motivated.
The reasoning for how the model was constructed is important.
It's like judging the food not only by taste, but also the cooking process: Did the chef use the right ingredients? Was the cooking time appropriate, and so on.


## Strengths

* Task-oriented, very practical. Can-do attitude.
* A job in machine learning potentially earns you lots of money.
* A computer-focused mindset in a computer-focused world. 
* Machine learning is predestined to automate tasks and build digital products.

## Limitations

* Not as principled as statistical modeling.
* A confusing amount of approaches with different motivations and technical foundations.
* A model that works well in solving a task is not necessarily a good model for insights. A model that predicts diabetes well may be useful, but less insightful than a statistical model that explicitly and understandably models the diabetes risk.
* Often data- and compute-intense.


[^computational-statistics]: There is a field called computational statistics, which is computer-oriented. But we are talking here about archetypes of mindsets. One can think of computational statistics as a statistical mindset, slightly infused with the machine learning mindset.

[^still-programmed]: I find it difficult to say that the machine learns by itself. Because also machine learning requires programming. You have to implement the learning part, and all the glue code to integrate the final model into the product.

