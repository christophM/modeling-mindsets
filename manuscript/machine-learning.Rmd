# Machine Learning and Artificial Intelligence {#machine-learning}

<!-- TODO

* Reread: End of Theory. https://www.wired.com/2008/06/pb-theory/ [@anderson2008end] -> This one is more general and might fit into the model chapter
* Read: https://hal.archives-ouvertes.fr/hal-03474791/
* Recreate Leo Breiman figure from Two cultures

-->

* Modeling is task-oriented and algorithmic.
* External validity more important than internal validity (aka stats).
* Lives from having lots of data
* A good model allows the computer to solve a task, make it look "intelligent".
* A model is connected to the real world by helping in solving a real task.
* Also a meta mindset and alternative to [statistical modeling](#statistical-ml). 
* [Supervised machine learning](#supervised-ml), [deep learning](#deep-learning) are specializations of this mindset.

<!-- metaphor -->
* machine learner
* statistician
* walk into amusement park
* they play game where you have to throw balls to win game
* 

Random notes

* Statistical models are based on their components they are build of.
* Machine learning models are based on how well they do their task, often involving prediction.
* 


Machine learners are a pragmatic people.
Task-oriented, and much less principled than the pure statisticians.
Statistics originated from pen and paper, evolving probability distributions from there.
The take-up of computer was because it was practical, and a natural step.

People with a machine learning mindset think of the computer from the start on.
I'm equating machine learning folks with artificial intelligence folks here.
They have the same goal -- make the computer more intelligent.
But machine learners say that taking this path requires learning from data.
The other paths that don't involve data, like expert systems, are not part of this book.



* task-driven and pragmantic mindset
* Make the computer do smart things
* less principled than statistical



Machine learning -- an umbrella term under which we find many things.
Deep learning, clustering, supervised machine learning, generative models and so on.

Machine learning is often defined as a branch of artificial intelligence.
Machine learning is about algorithms that improve themselves through the use of data.
Any algorithm that makes a machine seem intelligent, and which involves learning from data.
Which excludes things like expert systems.

What machine learning approaches have in common

* learn models from data. But then again, that's true for all mindsets in this book
* Improvement of some kind of algorithm.
* Som Task-driven rather than insight-driven.
* For example, the goal might be to cluster the data. If we were in the statistical modeling mindset, it would be important to think in probability distributions. But for machine learning mindset whatever get's the task done is fine. 
* "generalize from experience"
* computers make decisions
* type of artificial intelligence
* recognize patterns
* not being explcitly programmed
* trial and error
* "practice" and experience
* lots of data
* a good machine learning model is
  * one that helps you with some task
  * goal-driven
  * not important how you get there, but that you reach the goal
  * makes the computer look smart
  * algorithmic driven, not dgp driven. e.g. statisticians wouldn't use computers if they didn't had to. machine learning is more from the mindset that we have computers and now how can we make them smarter. see Breiman two cultures        
* statistics is much more principaled
* most theory about machine learning comes from intersection of stats and ml: statistical learning theory. mostly worked out for supervised ml. 
* starts with computer, and not with theory.
* how can we make computer intelligent.


## Diverse Mindsets Within ML

Within machine learning, the mindsets are quite diverse

There are supervised machine learner.
They wouldn't dare get their hands dirty with problems where no label is defined.

Interpretable machine learning folks share a lot of the mindset with supervised learners, as they usually work on supervised.
But they have the goal to find something out about the data.
They are willing to sacfrifice model performance for interpretability of the model.

Deep learner want to build everything with neural networks.
They work more with text and images.



## Model in Machine Learning


* What constitutes a model in machine learning varies wildly
* DBSCAN, statistical models, neural networks, support vector machines, ...
* Not so principled how to get there
* All models of course learned with data
* Tasks also vary wildly: Classification, Clustering, Regression, Image segmentation, language translations,  
* Often things are benchmarked in machine learning
  * For supervised ml it's the clearest bc there you have  clear metrics of success bc the true lables are known
  * For language models there is the BLEU score. stands for bi-lingual evaluation understudy, BLEU compares translation to human tranlsation.
  * in stats there is goodness-of-fit
  * task-related scores might also be used in stats, but the role is not as central
  * compared to stats the benchmarks 
* A good model solves a task with a computer algorithm and data
  * Want to caption images automatically? Goal is to find the best algorithm to do it.
* A good model of the world is one that emulates intelligence 
* A good model of the world is one that helps in solving a task
* How good the task is solved is determined by a score or so
* Scores naturally turn it into a competition between models
* Machine Learning is very "competitive" in the sense that the model with the best score wins.
 
## Generalizability

* ml has goal to do some task
* that includes that the models are generalizable to other data
* in supervised ml we can directly work with generalization error and that's the optimization goal there.






