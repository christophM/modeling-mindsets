# Machine Learning {#machine-learning}

<!-- TODO

* Reread: End of Theory. https://www.wired.com/2008/06/pb-theory/ [@anderson2008end] -> This one is more general and might fit into the model chapter
* Read: https://hal.archives-ouvertes.fr/hal-03474791/
* Write external vs. internal views
* Write about narrow AI mindset

-->


* Machine learning is task-oriented and algorithmic. A model is connected to the real world by helping in solving a real task.
* External validity more important than internal validity (aka stats).
* A computer-first mindset that allows computers to solve tasks and look "intelligent" in the process.
* Machine learning is a meta mindset and alternative to [statistical modeling](#statistical-ml). 
* [Supervised machine learning](#supervised-ml) and [deep learning](#deep-learning) are specializations of the machine learning mindset.


<!-- motivational introduction -->
It's likely that you used a machine learning powered product today.
You might have asked your smart assistant to read out your agenda for today, used a navigation app to get from A to B, or checked your mostly spam-free e-mails.
Machine learning is used in all these applications to make the product work: speech recognition, traffic jam prediction, and spam classification are just a few examples of what machine learning can help with.
These examples show that machine learning is very task-oriented.
Statistical modeling, in contrast, is more insight-oriented.

<!-- Artificial intelligence -->
For some, machine learning is not only task-oriented, but rather about making the computer intelligent.
Machine learning is the branch of artificial intelligence that is concerned with learning models directly from data.
The computer improves itself at some task through the "experience" aka by learning from data.
The machine learning mindset doesn't tell you **how** the computer shall learn from data.
Machine learner may or may not use random variables.
They might work on a prediction model with a clear definition of when the model is correct, or they might work on clustering where the model is more difficult to evaluate. 
The models can be neural networks, decision trees, density estimators, statistical models and many more.

<!-- not it's own mindset  -->
Given this broad set of tasks and no strict guidelines on how the computer has to learn: Can we really say that machine learning is it's own mindset?
To answer the question, let's first have a look at subsets of tasks.
Typically, machine learning is divided into supervised, unsupervised and reinforcement learning.
Supervised machine learning and reinforcement learning are good examples of distinct modeling mindsets: They contain a specific view on the world, the relationship between the models and the world, and how to judge what a good model is.
The [supervised machine learning](#supervised-ml) mindset frames everything as a prediction or classification problem, and comes with a clear definition of what a good model is: when it generalizes well to new data.
The [reinforcement learning](#reinforcement-learning) mindset sees the world as dynamic, where an actor interacts with an environment guided by a reward.
The troublemaker is unsupervised machine learning, which is basically defined as learning from data, and not falling into the category of unsupervised machine learning or reinforcement learning.
Unsupervised machine learning is any learning algorithm that does not use labels and is not framed as actor in an environment.
Unsupervised machine learning is like the random drawer in your house.
The "unsupervised" drawer at my home contains a Swiss knife, a bike lock, a reading lamp, ear plugs, a torch, ...
Maybe it's a bit to harsh.
Because there is one commonality between most unsupervised approaches.
Unsupervised machine learning techniques often have as result a description of the data distribution.
Clustering finds the center of the distributions, dimensionality reduction the features that are most important to describe the data distribution, anomaly detection detects data points that are outside of the distribution and so on. 
Is it then possible to frame all of machine learning, including the many-faced unsupervised machine learning as a coherent mindset?

<!-- yes, ml has core mindset -->
The machine learning mindset is not as united and principled as [statistical modeling](#statistical-modeling).
But all machine learning approaches have a few things in common.
So let's have a look at what machine learning has to say about what a good model is, and how , in the machine learning mindset, models are connected to the world.

<!-- ml is computer-driven -->
As all modeling mindsets in this book, machine learning is based on learning model from data.
As the name suggests, machine learning emphasizes the "machine", the computer.
Machine learning is about making the computer "learn" to solve tasks, such as prediction, recommendation, translation, and clustering.
How is that different from what statisticians do, who also rely on computers?
The motivation for using a computer differs between an archetypical statistician and an archetypical machine learner.
The statistician uses the computer out of convenience and necessity.
Most modern statistical models are only feasible because of the computer.
Statisticians start with statistical theory.
The computer is the aide that allows to apply the theory to data. [^computational-statistics]
The machine learner, in contrast, starts with the computer as the premise.
The machine learner says: "We have this new thing, the computer. How can we make it do intelligent and useful things?"
Machine learning is therefore a computer-first mindset.

<!-- algorithm-producing algorithm -->
Machine learning can be understood as a meta-algorithm: An algorithm that produces algorithms using data.
Machine learning produces algorithms, recipes that have an input and produce an output.
From a programmers standpoint, machine learning is a paradigm shift:
Machine learning is just a way to "learn" an algorithm from data, instead of programming it directly. [^still-programmed]

<!-- ml is task-driven -->
And machine learning is usually used to to some task.
So compared to the insights-driven statistical modeling, machine learning is often motivated by some problem that needs to be solved.
The task can be translation, image captioning, classification, and so on.
Since solving a task is the focus, it's less imported that the model produces insights like statistical models do, but success is measured in how well the task was solved.
A typical pattern in machine learning research is:
Invent some new algorithm.
Then the researchers show that the algorithm works on data, by showing that it beats some benchmark.
The reason why the algorithm works in the first place is often discovered only in later scientific publications.

<!-- external vs intrinsic motivation -->
It's a difference between external and intrinsic motivation (for the models, not the people).
The motivation and evaluation of a machine learning model is external, based on task performance.
It's like judging food based on how it tastes.
Statistical modeling is intrinsically motivated.
The reasoning for how the model was constructed is important.
It's like judging the food not only by taste, but also the cooking process: Did the chef use the right ingredients? Was the cooking time appropriate, and so on.
How well the task is solved is quantified by some metric.
The goodness of a machine learning model depends on the task it should do.
For prediction it is the generalization error for new data.
For classification it can be the accuracy of getting the right class.
For clustering it can be how homogeneous the clusters are.

## Many Mindsets Within Machine Learning

I know the chapter leaves you a bit hanging.
But the picture becomes much clearer when we consider subsets of machine learning as individual mindsets:

* [Supervised machine learning](#supervised-ml): They wouldn't dare get their hands dirty with problems where no label is defined.
* [Interpretable machine learning](#interpretable-ml):  Interpretable machine learning folks share a lot of the mindset with supervised learners, as they usually work on supervised. But they have the goal to find something out about the data. They are willing to sacfrifice model performance for interpretability of the model.
* [Deep learning](#deep-learning): Deep learner want to build everything with neural networks. They work more with text and images.
* [Reinforcement learning](#reinforcement-learning)

TODO: Add stub reinforcement learning
```{r ml-venn, fig.cap = "Machine Learning is a subset of artificial intelligence. Within machine learning, there is a an important mindset called supervised machine learning. Overlapping are deep learning approaches.", fig.height = 4, fig.width = 6}
library(ggplot2)
r1 = rectFun(c(0, 0), 2, 3)
r2 = rectFun(c(0.2, -0.1), 1.7, 2.5)
r3 = rectFun(c(0.9, -0.2), 1.4, 1)
r4 = rectFun(c(0.35, -0.4), 0.9, 2)

addBox = function(p, center, height, width, label, lty = 1){
  r1 = rectFun(center, height, width)
  labelpos = c(center[1] - width/2 + 0.05, center[2] + height/2 - 0.05) 
  p +
  geom_path(data = r1, lty = lty) + 
  annotate("text", labelpos[1], labelpos[2], label = label, hjust = 0, vjust = 1)
}


p = ggplot(mapping = aes(x,y)) + theme_void() 
p = addBox(p, c(0, 0), 2, 3, "Artificial Intelligence")
p = addBox(p, c(0.2, -0.1), 1.7, 2.5, "Machine Learning")
p = addBox(p, c(0.9, -0.2), 1.4, 1, "Deep Learning")
p = addBox(p, c(0.35, 0.1), 0.5, 2, "Reinforcement Learning")
p = addBox(p, c(0.35, -0.6), 0.5, 2, "Supervised Learning")

add_cc(p)
```


## Strengths

* Task-oriented, very practical. Can-do attitude.
* A job in machine learning jobs potentially earns you lots of money.
* A computer-focused mindset in a computer-focused world. 
* Allows to automate tasks.

## Limitations

* Not as principled as statistical modeling.
* A confusing amount of approaches with different motivations and technical foundations.
* A model that works well in solving a task is not necessarily a good model for understanding. A model that predicts diabetes well may be useful, but less insightful than a statistical model that explicitly and understandably models the diabetes risk.
* Often data- and compute-intense.


[^computational-statistics]: There is a field called computational statistics, which also thinks very compute-oriented. But we are talking here about archetypes of mindsets. One can think of computational statistics as a statistical mindset, slightly infused with the machine learning mindset.

[^still-programmed]: I find it difficult to say that the machine learns by itself. Because also machine learning requires programming. You have to implement the learning part, and all the glue code to integrate the final model into the product.

