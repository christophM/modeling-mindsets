\mainmatter

# Models 

<!-- motivation -->
You gaze at the screen.
The screen shows a table with some data.
Based on this data, you are to answer some questions.
These questions could be:

* Which patients might get side effects from a certain drug?
* How do bee hives react to a change in climate?
* Which supermarket products are often out-of-stock?

In the data you can see in detail what happened: patients with ID 124 and 22 got acne; 2/3 of bee colonies had trouble during drought in 2018; on that one Tuesday the flour was sold out;
But with data, you can't immediately see general rules and relationships.
Is flour generally in low supply at the beginning of the week?
It would be even better if these rules and relationships applied not only to your specific data sample, but to a more general population of patients/hives/supermarkets. 
To move from data to generalizable relationships, we have to simplify the world and make assumptions.
The end result is a model of the world based on data.

<!-- summary: what is a model -->
A model is a simplified representation of some aspect of the world.
For example, how bee colonies depend on climate.
With a model we can answer questions and make predictions that we couldn't with the raw data.

<!-- Exclusion criteria -->
In this book, we talk about certain types of models:
Models must be computational or mathematical models.
This excludes, for example, physical models, like the tiny houses that architects build.
The second restriction: The models are learned from data.
This excludes "designed" models such cellular automata.

<!-- What constitutes a model -->
There is no philosophical consensus on what makes a model.
For our purpose, let's say that **a mathematical model consists of three ingredients: variables, relations and parameters**.
<!-- in original text it's objects instead of variables -->
A mathematical model contains mathematical structures that represent *variables* and put them in *relation* (Figure \@ref(fig:model)). [^Weisberg2012]
The relations are often expressed as parameterized functions of the variables. 
The model **parameters** make the mathematical structure adaptable.
When the model is learned from data, in the learning process the parameters and sometimes relations (functions) are adapted to the data.
If you want to interpret models instead of the world, you have to make assumptions about the relationship between the model and aspects of the world.
But more about this in the chapter [Mindsets](#mindsets).

```{r model, cache = TRUE, fig.cap = "A mathematical model sets variables (dots) into relation (lines) using parameters."}
library(ggplot2)

nodes = data.frame(x = c(1, 3, 2),
                   y = c(2, 2, 3))

edges = data.frame(x =    c(2, 2, 3),
                   xend = c(1, 3, 1),
                   y =    c(3, 3, 2),
                   yend = c(2, 2, 2))
multi = 1.5
radius = 0.15 
edges$xend2 = edges$xend + c(radius, -radius, multi * radius)
edges$yend2 = edges$yend + c(radius, radius, 0)
edges$x2 = edges$x - c(radius, -radius, multi * radius)
edges$y2 = edges$y -  c(radius, radius, 0)

ggplot(mapping = aes(x = x, y = y)) +
  geom_segment(aes(xend = xend2, yend = yend2, x = x2, y = y2), data = edges, color = "black", size = 1) +
  geom_point(size = 20, color = "darkgrey", data = nodes) +
  annotate("text", label = "alpha", x = 1.4, y = 2.6, parse = TRUE,  size = 10) +
  annotate("text", label = "beta",  x = 2.6, y = 2.6, parse = TRUE, size = 10) +
  annotate("text", label = "gamma", x = 2, y = 1.9, parse = TRUE, size = 10) +
  theme_void() +
  scale_y_continuous("", limits = c(1.7,3.3)) +
  scale_x_continuous("", limits = c(0.7,3.3)) +
  coord_fixed()

```

<!-- variables -->
The aspects of the world are represented within the model as *variables*.
The blood pressure of a patient is represented with a numerical value.
Images, for example, are represented as tensors of pixels.
Variables can also represent a latent, hidden or abstract aspect.
Like happiness or introversion.
There are different names for variables:
Random variables, covariates, predictors, latent variables, features, target, outcome,  ...
These names sometimes reveal the role of a variable in the model.
For example, the "target" is the variable that we want to predict.
In different mindsets, variables have different names and roles:
In machine learning, for example, the terms feature and target are used.
In statistics, people might say dependent and independent variable or covariates and outcome instead.

<!-- relation -->
Within the model, the components are mathematically or computationally set in *relation* to each other.
These relations are usually expressed as parameterized functions.
For example:

* Causal models represent relations between variables in a directed acyclic graph that can be translated into conditional (in-)dependencies.
* The joint distribution of variables describes the occurrence of certain variable values in a probabilist sense.
* A predictive model represents the output variable as a parameterized function of the input variables.
* In the case of a linear regression model, the output variable is a weighted sum of the input variables.

<!-- TODO: visualize different functions? -->

<!-- expressiveness of relations -->
The expressive power of such relationships really depends on the class of the model.
A relation can be a simple linear equation like $Y = 5 \cdot X$ involving two or more variables.
For example we might model the probability of a stroke as a function of blood pressure and age. 
A relation can also be a long chain of mathematical operations involving thousands of variables.
Deep neural networks are an example of such a complicated relation.

<!-- parameters and structures -->
We don't know the relations between variables in advance, so we use data to learn them.
For some models, learning these relationships is a matter of finding the right *parameters*.
This is true for neural networks and generalized additive models, for example.
For other models, the model structure is "grown", as in decision trees or support vector machines.
Growing the structure means not only learning parameters, but also learning the structure of the mathematical function.

<!-- instantiation -->
You can think of a model as having an uninstantiated state and an instantiated state.
An uninstantiated model is not yet fitted to the data.
Uninstantiated models form families of models.
For example the neural network ResNet architecture, or the family of Poisson regression models.
An instantiated model is trained / learned / fitted using data: It's parameterized and/or the structure has been learned.

<!-- parameters example -->
I can buy carrots with money.
How many grams of carrots can I get for 1 euro?
Let's call this unknown parameter in our equation $\beta$:
$1 \text{ EUR} = \beta \text{ Carrots}$.
I could figure out the $\beta$ by going to the supermarket and checking the price.
Maybe $\beta = 500$, so I get half a kilogram of carrots for 1 euro.
But that's only for one supermarket!
Maybe I have to add more variables and relations to the model.
Maybe I need to consider the supermarket chain, special deals, organic / non-organic, ...
All these choices add variables, relations and parameters to the model.

<!-- 
There are many different types and names for parameters.
Sometimes they just describe a distribution, like the mean of distribution.
Or they describe the relationship between two variables, like regression coefficient.
Or it's a weight in a neural network.

What's different is hyperparameters.
In a sense, they exist outside of what the model describes.
Hyperparameters set how the learning from data takes place.
-->


<!-- making use of the model -->
What we can do with the model depends on the modeling mindset.
In supervised machine learning, we take advantage of the modeled relations to make predictions.
In causal inference, we use our model to estimate causal effects.
In likelihoodism, we can compare the likelihoods between models.


<!--

## Tasks

There are different tasks

* Regression:
* Classification:
* Clustering:
* Outlier detection:
* Pattern recognition:

The tasks are not perfectly seperable from the models and mindsets.
Because some mindsets are more concentrated on some of the tasks.



-->

[^Weisberg2012]: Weisberg, Michael. Simulation and similarity: Using models to understand the world. Oxford University Press, 2012.

